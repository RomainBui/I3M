{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "I3M by R3",
      "provenance": [],
      "collapsed_sections": [
        "mp8nvnSgr_Bl",
        "POZpNGARp1yV",
        "MA6fcj2fp1yb",
        "-YB98jKFyhPs",
        "2kBhxzCXPYJU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RomainBui/I3M/blob/main/I3M_by_R3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL8hYgN5p1yM"
      },
      "source": [
        "# I3M Computation by 3R\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBfkphoH5XM9"
      },
      "source": [
        "This project will perform the mask_RCNN inference of MT in order to eventually compute I3M"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "E2L01ItCs2AF"
      },
      "source": [
        "#@title Configuration { run: \"auto\" }\n",
        "run_mode = \"Inference\" #@param [\"Inference\", \"Comparison inference / manual\", \"I3M on manual segmentation\"]\n",
        "endpoints_detection_method = \"Gradient\" #@param [\"Ray tracing\", \"Skeleton\", \"Gradient\", \"Ray tracing + skeleton\", \"All\"]\n",
        "HD = \"Image already HD\" #@param [\"Apply HD filter\", \"Image already HD\"]\n",
        "debug = False #@param {type: \"boolean\" }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp8nvnSgr_Bl"
      },
      "source": [
        "## Select Model + Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsCQrGOqkBWb",
        "outputId": "1116ce76-8b44-4a7c-ac5f-86b60a009a53"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KnEJyrSEr2J7",
        "outputId": "77d50df3-6f6e-4421-b73a-147a843b9b9f"
      },
      "source": [
        "!rm /content/*.jpg || {}\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print('please select your Images and/or Manual segmentations')\n",
        "uploaded = files.upload()\n",
        "filenames = list(uploaded.keys())\n",
        "image_filenames = [filename for filename in filenames if filename.endswith('.jpg') or filename.endswith('.png')]\n",
        "manual_segmentation_filenames = [filename for filename in filenames if filename.endswith('.json')]\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "please select your Images and/or Manual segmentations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e906184-4d5a-4ba9-9acd-37384a577a06\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2e906184-4d5a-4ba9-9acd-37384a577a06\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 414_l.jpg to 414_l.jpg\n",
            "Saving 414_l.json to 414_l.json\n",
            "Saving 417_r.jpg to 417_r.jpg\n",
            "Saving 417_r.json to 417_r (1).json\n",
            "Saving 418_r.jpg to 418_r.jpg\n",
            "Saving 418_r.json to 418_r.json\n",
            "Saving 419_l.jpg to 419_l.jpg\n",
            "Saving 419_l.json to 419_l.json\n",
            "Saving 420_r.jpg to 420_r.jpg\n",
            "Saving 420_r.json to 420_r.json\n",
            "Saving 421_r.jpg to 421_r.jpg\n",
            "Saving 421_r.json to 421_r.json\n",
            "Saving 427_l.jpg to 427_l.jpg\n",
            "Saving 427_l.json to 427_l.json\n",
            "Saving 429_r.jpg to 429_r.jpg\n",
            "Saving 429_r.json to 429_r.json\n",
            "Saving 432_l.jpg to 432_l.jpg\n",
            "Saving 432_l.json to 432_l.json\n",
            "Saving 433_l.jpg to 433_l.jpg\n",
            "Saving 433_l.json to 433_l.json\n",
            "Saving 439_r.jpg to 439_r.jpg\n",
            "Saving 439_r.json to 439_r.json\n",
            "Saving 442_l.jpg to 442_l.jpg\n",
            "Saving 442_l.json to 442_l.json\n",
            "Saving 444_l.jpg to 444_l.jpg\n",
            "Saving 444_l.json to 444_l.json\n",
            "Saving 446_l.jpg to 446_l.jpg\n",
            "Saving 446_l.json to 446_l.json\n",
            "Saving 454_r.jpg to 454_r.jpg\n",
            "Saving 454_r.json to 454_r.json\n",
            "Saving 470_r.jpg to 470_r.jpg\n",
            "Saving 470_r.json to 470_r.json\n",
            "Saving 472_l.jpg to 472_l.jpg\n",
            "Saving 472_l.json to 472_l.json\n",
            "Saving 479_r.jpg to 479_r.jpg\n",
            "Saving 479_r.json to 479_r.json\n",
            "Saving 484_l.jpg to 484_l.jpg\n",
            "Saving 484_l.json to 484_l.json\n",
            "Saving 486_l.jpg to 486_l.jpg\n",
            "Saving 486_l.json to 486_l.json\n",
            "Saving 486_r.jpg to 486_r.jpg\n",
            "Saving 486_r.json to 486_r.json\n",
            "Saving 488_l.jpg to 488_l.jpg\n",
            "Saving 488_l.json to 488_l.json\n",
            "Saving 510_l.jpg to 510_l.jpg\n",
            "Saving 510_l.json to 510_l.json\n",
            "Saving 515_r.jpg to 515_r.jpg\n",
            "Saving 515_r.json to 515_r.json\n",
            "Saving 524_l.jpg to 524_l.jpg\n",
            "Saving 524_l.json to 524_l.json\n",
            "Saving 524_r.jpg to 524_r.jpg\n",
            "Saving 524_r.json to 524_r.json\n",
            "User uploaded file \"414_l.jpg\" with length 9877 bytes\n",
            "User uploaded file \"414_l.json\" with length 23723 bytes\n",
            "User uploaded file \"417_r.jpg\" with length 10703 bytes\n",
            "User uploaded file \"417_r.json\" with length 21880 bytes\n",
            "User uploaded file \"418_r.jpg\" with length 13136 bytes\n",
            "User uploaded file \"418_r.json\" with length 27805 bytes\n",
            "User uploaded file \"419_l.jpg\" with length 9979 bytes\n",
            "User uploaded file \"419_l.json\" with length 21444 bytes\n",
            "User uploaded file \"420_r.jpg\" with length 10555 bytes\n",
            "User uploaded file \"420_r.json\" with length 23114 bytes\n",
            "User uploaded file \"421_r.jpg\" with length 10005 bytes\n",
            "User uploaded file \"421_r.json\" with length 22679 bytes\n",
            "User uploaded file \"427_l.jpg\" with length 8513 bytes\n",
            "User uploaded file \"427_l.json\" with length 19194 bytes\n",
            "User uploaded file \"429_r.jpg\" with length 9223 bytes\n",
            "User uploaded file \"429_r.json\" with length 24869 bytes\n",
            "User uploaded file \"432_l.jpg\" with length 10568 bytes\n",
            "User uploaded file \"432_l.json\" with length 26332 bytes\n",
            "User uploaded file \"433_l.jpg\" with length 12004 bytes\n",
            "User uploaded file \"433_l.json\" with length 24865 bytes\n",
            "User uploaded file \"439_r.jpg\" with length 9079 bytes\n",
            "User uploaded file \"439_r.json\" with length 20499 bytes\n",
            "User uploaded file \"442_l.jpg\" with length 9204 bytes\n",
            "User uploaded file \"442_l.json\" with length 22418 bytes\n",
            "User uploaded file \"444_l.jpg\" with length 10025 bytes\n",
            "User uploaded file \"444_l.json\" with length 24219 bytes\n",
            "User uploaded file \"446_l.jpg\" with length 9533 bytes\n",
            "User uploaded file \"446_l.json\" with length 20936 bytes\n",
            "User uploaded file \"454_r.jpg\" with length 8247 bytes\n",
            "User uploaded file \"454_r.json\" with length 18656 bytes\n",
            "User uploaded file \"470_r.jpg\" with length 9863 bytes\n",
            "User uploaded file \"470_r.json\" with length 30427 bytes\n",
            "User uploaded file \"472_l.jpg\" with length 13950 bytes\n",
            "User uploaded file \"472_l.json\" with length 35097 bytes\n",
            "User uploaded file \"479_r.jpg\" with length 8855 bytes\n",
            "User uploaded file \"479_r.json\" with length 31243 bytes\n",
            "User uploaded file \"484_l.jpg\" with length 13504 bytes\n",
            "User uploaded file \"484_l.json\" with length 34578 bytes\n",
            "User uploaded file \"486_l.jpg\" with length 9278 bytes\n",
            "User uploaded file \"486_l.json\" with length 25010 bytes\n",
            "User uploaded file \"486_r.jpg\" with length 8831 bytes\n",
            "User uploaded file \"486_r.json\" with length 23192 bytes\n",
            "User uploaded file \"488_l.jpg\" with length 9600 bytes\n",
            "User uploaded file \"488_l.json\" with length 24144 bytes\n",
            "User uploaded file \"510_l.jpg\" with length 11902 bytes\n",
            "User uploaded file \"510_l.json\" with length 28117 bytes\n",
            "User uploaded file \"515_r.jpg\" with length 8548 bytes\n",
            "User uploaded file \"515_r.json\" with length 23228 bytes\n",
            "User uploaded file \"524_l.jpg\" with length 8850 bytes\n",
            "User uploaded file \"524_l.json\" with length 24695 bytes\n",
            "User uploaded file \"524_r.jpg\" with length 9091 bytes\n",
            "User uploaded file \"524_r.json\" with length 22237 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMZuUZFovoGI"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0kFZGg0xl-8"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"10jP0flXeozBQUXcx6Q7CUonaQiTZAjrV\"})  # I3M - JUNE 2021\n",
        "#downloaded = drive.CreateFile({'id':\"1CAn1PBg_OrGhN41LP51UNY46zTsi3xo-\"})  # mask_rcnn_tooth_segmentation_0006\n",
        "#downloaded = drive.CreateFile({'id':\"19euYX5zo1ty5HacZ0mwXuUoHygFaWLkV\"}) # mask_rcnn_tooth_segmentation_0008\n",
        "#downloaded = drive.CreateFile({'id':\"1o6uigkw3ZSN2H1vBRv5-uqLX3UiD7m-w\"}) # mask_rcnn_tooth_segmentation_0018\n",
        "#downloaded = drive.CreateFile({'id':\"1eFsvwd7knZBOpUTO_7iwIcipnvE7Cq1W\"}) # mask_rcnn_tooth_segmentation_0019\n",
        "\n",
        "downloaded.GetContentFile('I3M.h5')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POZpNGARp1yV"
      },
      "source": [
        "## Install backbone in Google Colab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYnZTLMgp1yV"
      },
      "source": [
        "#%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PVdnlB7p1yY",
        "outputId": "b756eb10-bdeb-4fe0-b881-12efa65e455a"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN\n",
        "%cd Mask_RCNN\n",
        "!pip3 install -r requirements.txt\n",
        "!python3 setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n",
            "/content/Mask_RCNN\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.23)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.18.1)\n",
            "Requirement already satisfied: tensorflow>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.15.0rc2)\n",
            "Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.2.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.10.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n",
            "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.34.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2021.7.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: ipyparallel in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (6.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: nose>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.3.7)\n",
            "Requirement already satisfied: Sphinx>=1.3 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.2.5)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.9.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (21.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.11.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.1.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (0.17.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (1.2.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->IPython[all]->-r requirements.txt (line 12)) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from ipyparallel->IPython[all]->-r requirements.txt (line 12)) (22.1.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->IPython[all]->-r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->IPython[all]->-r requirements.txt (line 12)) (1.0.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->IPython[all]->-r requirements.txt (line 12)) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->IPython[all]->-r requirements.txt (line 12)) (0.10.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->IPython[all]->-r requirements.txt (line 12)) (1.7.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->IPython[all]->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->IPython[all]->-r requirements.txt (line 12)) (1.9.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (1.1.5)\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/mask_rcnn-2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Copying mask_rcnn-2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txm9YcQPp1yZ",
        "outputId": "2667c803-9091-4240-f954-d7e9e0199135"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!make\n",
        "%cd ../../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cocoapi' already exists and is not an empty directory.\n",
            "/content/Mask_RCNN/cocoapi/PythonAPI\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n",
            "/content/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kkJgQ5CTiAn",
        "outputId": "955520c6-d3d8-4cbd-cece-facdfff01bb0"
      },
      "source": [
        "!git clone https://www.github.com/iozzinor/Apex_points\n",
        "!pip3 install scikit-image==0.18.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Apex_points' already exists and is not an empty directory.\n",
            "Requirement already satisfied: scikit-image==0.18.1 in /usr/local/lib/python3.7/dist-packages (0.18.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (2.5.1)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (1.19.5)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (2021.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image==0.18.1) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ywia4bNnG0Q",
        "outputId": "f0575d2e-03d8-4b48-fcc0-c7cb99151de8"
      },
      "source": [
        "!pip3 uninstall -y keras-nightly\n",
        "!pip3 uninstall -y keras\n",
        "!pip3 install keras==2.2.5\n",
        "\n",
        "#!pip3 uninstall -y tensorflow\n",
        "!pip3 install tensorflow==1.15.0rc2\n",
        "\n",
        "!pip3 install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "Found existing installation: Keras 2.2.5\n",
            "Uninstalling Keras-2.2.5:\n",
            "  Successfully uninstalled Keras-2.2.5\n",
            "Collecting keras==2.2.5\n",
            "  Using cached Keras-2.2.5-py2.py3-none-any.whl (336 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.5\n",
            "Requirement already satisfied: tensorflow==1.15.0rc2 in /usr/local/lib/python3.7/dist-packages (1.15.0rc2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.34.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.19.5)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0rc2) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (57.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.7.4.3)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA6fcj2fp1yb"
      },
      "source": [
        "## Import and Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sVT6Z0OrGKX",
        "outputId": "020cf27a-5b4c-415f-d9b3-dcdc05bb71e8"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "import Apex_points\n",
        "from Apex_points.ray_tracing import localize_apices_engine as ray_tracing_engine\n",
        "from Apex_points.skeleton import localize_apices_engine as skeleton_engine\n",
        "from Apex_points.gradient import localize_apices_engine as gradient_engine\n",
        "\n",
        "import traceback"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dGBBIAVrPtD",
        "outputId": "729b562a-aa5a-4258-f4bb-ecd0e83e4880"
      },
      "source": [
        "## UPDATE WT\n",
        "class RadioConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"tooth_segmentation\"\n",
        "    \n",
        "    NUM_CLASSES = 1 + 1 #NB : 2 because MT and JAD\n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    STEPS_PER_EPOCH = 250\n",
        "\n",
        "    # New\n",
        "    IMAGE_MAX_DIM = 256\n",
        "    IMAGE_MIN_DIM = 256\n",
        "\n",
        "config = RadioConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  256\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  256\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [256 256   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           tooth_segmentation\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                250\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YB98jKFyhPs"
      },
      "source": [
        "## Inference production"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3zL0OJXzLyR",
        "outputId": "f8fe5e54-7d82-4f71-d03a-b9d1a940075f"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8mFOKTpylRy",
        "outputId": "dccad9a6-e8cd-45b3-95d5-87ec54995c85"
      },
      "source": [
        "MODEL_DIR = \"\"\n",
        "class InferenceConfig(RadioConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = \"I3M.h5\"\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "Loading weights from  I3M.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVQEn_fo1a-v"
      },
      "source": [
        "import numpy as np\n",
        "from skimage.morphology import skeletonize\n",
        "from skimage import exposure\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "\n",
        "cnames = ['BG', 'MT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjI2WcPv2kRY"
      },
      "source": [
        "# Romain - add on : create dict\n",
        "#\n",
        "# Regis - edit: store results in the global variable as dictionnaries. dict_res is no longer a list but a dict, whose keys are the radio UNIQUE identifiers\n",
        "# Advantages: no longer need to maintain two arrays side by side ('Radio_ID' and 'I3M') with the need to have same length and order\n",
        "\n",
        "# Regis - 2021/07/05\n",
        "# updated the apex_localize result dictionnary\n",
        "dict_res = {}\n",
        "\n",
        "def _combine_engine(engine_ids, image, mt_masks, debug=False, output_dir='.', image_name=''):\n",
        "  import statistics\n",
        "  from Apex_points.ray_tracing.image_merger import ImageMerger\n",
        "\n",
        "  image_merger = ImageMerger()\n",
        "\n",
        "  all_results = [engines[engine_id](image, mt_masks, debug=debug, output_dir=output_dir, image_name=image_name) for engine_id in engine_ids]\n",
        "  combined_result = { 'I3M': -1, 'min_apex_opening': -1, 'max_apex_opening': -1, 'height': -1 }\n",
        "\n",
        "  for i, engine_id in enumerate(engine_ids):\n",
        "    output_image = all_results[i]['output_image'] if all_results[i]['output_image'] is not None else Image.new('RBG', (16, 16))\n",
        "    image_merger.add_image(output_image, engine_id)\n",
        "\n",
        "  apices_result = [apex_result for apex_result in all_results if apex_result is not None]\n",
        "  for key in ['I3M', 'min_apex_opening', 'max_apex_opening', 'height']:\n",
        "      combined_result[key] = statistics.mean([apex_result[key] for apex_result in apices_result if key in apex_result])\n",
        "  result_image = image_merger.generate_image()\n",
        "  combined_result['output_image'] = result_image\n",
        "  if debug:\n",
        "    result_image.save(os.path.join(output_dir, f'{image_name}-debug.png'))\n",
        "\n",
        "  return combined_result\n",
        "\n",
        "def _ray_tracing_plus_skeleton_engine(image, mt_masks, debug=False, output_dir='.', image_name=''):\n",
        "  return _combine_engine(['Ray tracing', 'Skeleton'], image, mt_masks, debug, output_dir, image_name)\n",
        "\n",
        "def _all_engine(image, mt_masks, debug=False, output_dir='.', image_name=''):\n",
        "  return _combine_engine(['Ray tracing', 'Skeleton', 'Gradient'], image, mt_masks, debug, output_dir, image_name)\n",
        "\n",
        "engines = { 'Ray tracing': ray_tracing_engine, 'Skeleton': skeleton_engine, 'Gradient': gradient_engine, 'Ray tracing + skeleton': _ray_tracing_plus_skeleton_engine, 'All': _all_engine }\n",
        "\n",
        "def adaptHist(path_image): \n",
        "    img_to_pred_arr = np.array(Image.open(path_image).convert('RGB'))\n",
        "    img_to_pred_adapthist = exposure.equalize_adapthist(img_to_pred_arr/np.max(img_to_pred_arr))\n",
        "    img_to_pred_adapthist = Image.fromarray((img_to_pred_adapthist * 255).astype(np.uint8))\n",
        "    return img_to_pred_adapthist\n",
        "\n",
        "def make_predictions(image_paths):\n",
        "  \"\"\"\n",
        "  Returns\n",
        "  -------\n",
        "    The result of the function `make_visualisations`\n",
        "  \"\"\"\n",
        "  #images = [Image.open(image_path).convert('RGB') for image_path in image_paths]\n",
        "  #names = [os.path.splitext(os.path.basename(filename))[0] for filename in image_paths]\n",
        "  #np_images = [np.array(image) for image in images]\n",
        "  \n",
        "  if(HD==\"Image already HD\"):\n",
        "    images = [Image.open(image_path).convert('RGB') for image_path in image_paths]\n",
        "  else: \n",
        "    images = [adaptHist(image_path) for image_path in image_paths]\n",
        "\n",
        "  names = [os.path.splitext(os.path.basename(filename))[0] for filename in image_paths]\n",
        "  np_images = [np.array(image) for image in images]\n",
        "  \n",
        "  results = [model.detect([image], verbose=1) for image in np_images]\n",
        "  return make_visualizations(results, images, names)\n",
        "\n",
        "def make_visualizations(results, images, names):\n",
        "   \"\"\"\n",
        "   Returns\n",
        "   -------\n",
        "   An array of the results returned by `make_prediction_image`\n",
        "   \"\"\"\n",
        "   return [make_prediction_image(r[0], i, name) for r, i, name in zip(results, images, names)]\n",
        "\n",
        "def make_prediction_image(r, img_to_pred, image_name, dict_res=dict_res):\n",
        "  \"\"\"\n",
        "  Returns\n",
        "  -------\n",
        "    None in case of failure.\n",
        "    Else: a tupple of :\n",
        "    - the output image, as a PILLOW object.\n",
        "    - the prediction engine result\n",
        "    - the model result\n",
        "    - an array of the mineralized tissue masks\n",
        "  \"\"\"\n",
        "  # masks has a shape (height, width, number of detected classes)\n",
        "  masks = r['masks']\n",
        "  # masks is now an array with 'number of detected classes' elements\n",
        "  # each element has a shape (height, width)\n",
        "  masks_count = masks.shape[-1]\n",
        "  masks = [mask.reshape((config.IMAGE_MAX_DIM, config.IMAGE_MAX_DIM)) for mask in np.split(masks, masks_count, axis=-1)]\n",
        "  class_ids = r['class_ids']\n",
        "  mt_masks = []\n",
        "  for i, mask in enumerate(masks):\n",
        "      current_class_name = cnames[class_ids[i]]\n",
        "      if current_class_name == 'MT':\n",
        "          mt_masks.append(mask)\n",
        "\n",
        "  apices_result = Apex_points.localize_apices(img_to_pred, mt_masks, engines[endpoints_detection_method], debug, '.', image_name)\n",
        "  if apices_result is not None:\n",
        "    dict_res[image_name] = {}\n",
        "    for key in ['I3M', 'min_apex_opening', 'max_apex_opening', 'height']:\n",
        "      if key in apices_result:\n",
        "        dict_res[image_name][key] = apices_result[key]\n",
        "    return apices_result['output_image'], apices_result, r, mt_masks\n",
        "  return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxAuMhSQs1wu"
      },
      "source": [
        "image_paths = image_filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVQWmvV12xeu",
        "outputId": "8bc2acb2-7d8a-45a1-db4e-5a9c80b4521f"
      },
      "source": [
        "%cd /content\n",
        "result_predictions = make_predictions(image_filenames)\n",
        "\n",
        "result_images = []\n",
        "for result in result_predictions:\n",
        "  try: \n",
        "    result_images.append(result[0])\n",
        "  except:\n",
        "    result_images.append(None)\n",
        "#result_images = [result[0] for result in result_predictions]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
            "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-26 14:50:23,309 - Apex points - ERROR - exception during treatment of 421_r: 2 MT masks are needed to infer\n",
            "2021-07-26 14:50:23,316 - Apex points - ERROR - Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/Apex_points/utils.py\", line 350, in localize_apices\n",
            "    result = engine(image, mt_masks, debug, output_dir, image_name)\n",
            "  File \"/content/Mask_RCNN/Apex_points/gradient/gradient.py\", line 202, in localize_apices_engine\n",
            "    raise ValueError('2 MT masks are needed to infer')\n",
            "ValueError: 2 MT masks are needed to infer\n",
            "\n",
            "2021-07-26 14:50:30,226 - Apex points - ERROR - exception during treatment of 433_l: 2 MT masks are needed to infer\n",
            "2021-07-26 14:50:30,228 - Apex points - ERROR - Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/Apex_points/utils.py\", line 350, in localize_apices\n",
            "    result = engine(image, mt_masks, debug, output_dir, image_name)\n",
            "  File \"/content/Mask_RCNN/Apex_points/gradient/gradient.py\", line 202, in localize_apices_engine\n",
            "    raise ValueError('2 MT masks are needed to infer')\n",
            "ValueError: 2 MT masks are needed to infer\n",
            "\n",
            "2021-07-26 14:50:51,144 - Apex points - ERROR - exception during treatment of 486_l: 2 MT masks are needed to infer\n",
            "2021-07-26 14:50:51,146 - Apex points - ERROR - Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/Apex_points/utils.py\", line 350, in localize_apices\n",
            "    result = engine(image, mt_masks, debug, output_dir, image_name)\n",
            "  File \"/content/Mask_RCNN/Apex_points/gradient/gradient.py\", line 202, in localize_apices_engine\n",
            "    raise ValueError('2 MT masks are needed to infer')\n",
            "ValueError: 2 MT masks are needed to infer\n",
            "\n",
            "2021-07-26 14:50:59,327 - Apex points - ERROR - exception during treatment of 524_l: 2 MT masks are needed to infer\n",
            "2021-07-26 14:50:59,331 - Apex points - ERROR - Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/Apex_points/utils.py\", line 350, in localize_apices\n",
            "    result = engine(image, mt_masks, debug, output_dir, image_name)\n",
            "  File \"/content/Mask_RCNN/Apex_points/gradient/gradient.py\", line 202, in localize_apices_engine\n",
            "    raise ValueError('2 MT masks are needed to infer')\n",
            "ValueError: 2 MT masks are needed to infer\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD2QKX8R2yV2",
        "outputId": "2c93c593-e4f3-45da-83f8-f58287754761"
      },
      "source": [
        "# save the results\n",
        "![ -d Predictions ] || mkdir Predictions\n",
        "for i, result_image in enumerate(result_images):\n",
        "  if result_image is None:\n",
        "    print(f'image at index {i} is None')\n",
        "    continue\n",
        "  try: \n",
        "    filename = image_filenames[i]\n",
        "    image_name, image_extension = os.path.splitext(filename) # get the image name from the filename\n",
        "    image_extension = image_extension[1:] # remove the leading dot\n",
        "\n",
        "    output_path = os.path.join('Predictions', f'{image_name}-pred-{endpoints_detection_method}.{image_extension}')\n",
        "    result_image.save(output_path, quality=100, subsampling=0)\n",
        "    print(f'saved result at {output_path}')\n",
        "  except Exception as exception:\n",
        "    print(f'error in saving: {exception}')\n",
        "    print(traceback.format_exc())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved result at Predictions/414_l-pred-Gradient.jpg\n",
            "saved result at Predictions/417_r-pred-Gradient.jpg\n",
            "saved result at Predictions/418_r-pred-Gradient.jpg\n",
            "saved result at Predictions/419_l-pred-Gradient.jpg\n",
            "saved result at Predictions/420_r-pred-Gradient.jpg\n",
            "image at index 5 is None\n",
            "saved result at Predictions/427_l-pred-Gradient.jpg\n",
            "saved result at Predictions/429_r-pred-Gradient.jpg\n",
            "saved result at Predictions/432_l-pred-Gradient.jpg\n",
            "image at index 9 is None\n",
            "saved result at Predictions/439_r-pred-Gradient.jpg\n",
            "saved result at Predictions/442_l-pred-Gradient.jpg\n",
            "saved result at Predictions/444_l-pred-Gradient.jpg\n",
            "saved result at Predictions/446_l-pred-Gradient.jpg\n",
            "saved result at Predictions/454_r-pred-Gradient.jpg\n",
            "saved result at Predictions/470_r-pred-Gradient.jpg\n",
            "saved result at Predictions/472_l-pred-Gradient.jpg\n",
            "saved result at Predictions/479_r-pred-Gradient.jpg\n",
            "saved result at Predictions/484_l-pred-Gradient.jpg\n",
            "image at index 19 is None\n",
            "saved result at Predictions/486_r-pred-Gradient.jpg\n",
            "saved result at Predictions/488_l-pred-Gradient.jpg\n",
            "saved result at Predictions/510_l-pred-Gradient.jpg\n",
            "saved result at Predictions/515_r-pred-Gradient.jpg\n",
            "image at index 24 is None\n",
            "saved result at Predictions/524_r-pred-Gradient.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APcPffdA-fhI"
      },
      "source": [
        "if debug:\n",
        "  _show_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLxeFQVK8F7T"
      },
      "source": [
        "## Comparison inference / manual (if applicable: see `run_mode`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYl62gnYYaLj"
      },
      "source": [
        "from itertools import compress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO8rP5V75LKX"
      },
      "source": [
        "![ -d Manual_comparison ] || mkdir Manual_comparison\n",
        "\n",
        "%matplotlib inline\n",
        "# Regis - add on: compute area accuracy\n",
        "\n",
        "import logging\n",
        "import json\n",
        "\n",
        "def _create_merged_mask(mt_masks):\n",
        "  # create the composite image (logical or of all masks)\n",
        "  mt_mask = np.zeros_like(mt_masks[0])\n",
        "  for mask in mt_masks:\n",
        "    mt_mask |= mask\n",
        "  return mt_mask\n",
        "\n",
        "def _shapes_to_masks(shapes, width, height):\n",
        "  masks = []\n",
        "  for shape in shapes:\n",
        "    mask = Image.new('L', (width, height))\n",
        "    points = [tuple(point) for point in shape['points']]\n",
        "    ImageDraw.Draw(mask).polygon(points, fill=1)\n",
        "    masks.append(np.array(mask))\n",
        "  return masks\n",
        "\n",
        "  masks = np.zeros((height, width))\n",
        "\n",
        "def _json_file_to_mt_masks(json_filename):\n",
        "    with open(json_filename) as json_file:\n",
        "      annotations = json.load(json_file)\n",
        "    shapes = annotations['shapes']\n",
        "    mt_shapes = [shape for shape in shapes if shape['label'] == 'MT']\n",
        "    mt_masks = _shapes_to_masks(mt_shapes, annotations['imageWidth'], annotations['imageHeight'])\n",
        "    return mt_masks\n",
        "\n",
        "def _json_file_to_mt_mask(json_filename):\n",
        "    return _create_merged_mask(_json_file_to_mt_masks(json_filename))\n",
        "\n",
        "def _number_pixels_in_mask(mask):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  mask: np.array\n",
        "    A binary mask (or an int mask: any strict positive value will be considered as True).\n",
        "  \"\"\"\n",
        "  return len(list(zip(*np.where(mask>0))))\n",
        "\n",
        "def _compare_accuracy(ground_truth_mask, prediction_mask):\n",
        "  \"\"\"\n",
        "  Compare pixels from the ground truth mask and the prediction one.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  A tupple: (accuracy_image, stats)\n",
        "  \"\"\"\n",
        "  union = ground_truth_mask | prediction_mask\n",
        "  intersection = ground_truth_mask & prediction_mask\n",
        "\n",
        "  tp_mask = intersection\n",
        "  tn_mask = np.where(union>0,0,1)\n",
        "  fp_mask = union & np.where(ground_truth_mask>0,0,1)\n",
        "  fn_mask = union & np.where(prediction_mask>0,0,1)\n",
        "\n",
        "  accuracy_image = Image.new('RGB', (union.shape[1], union.shape[0]))\n",
        "  # TODO: refactoriser bibliothèque Apex_points pour ne plus appeler la fonction \"privée\" Apex_points.utils._apply_mask_to_image.\n",
        "  Apex_points.utils._apply_mask_to_image(accuracy_image, tp_mask, (0, 255, 0), 1) # true positives: green\n",
        "  Apex_points.utils._apply_mask_to_image(accuracy_image, tn_mask, (0, 0, 0), 1) # true negatives: black\n",
        "  Apex_points.utils._apply_mask_to_image(accuracy_image, fn_mask, (255, 0, 0), 1) # false negatives (missing pixels): red\n",
        "  Apex_points.utils._apply_mask_to_image(accuracy_image, fp_mask, (255, 128, 0), 1) # false positives: orange\n",
        "\n",
        "  stat_masks = {'TP': tp_mask, 'TN': tn_mask, 'FP': fp_mask, 'FN': fn_mask}\n",
        "\n",
        "  stats = {}\n",
        "  for (key, mask) in stat_masks.items():\n",
        "    stats[key] = _number_pixels_in_mask(mask)\n",
        "  return (accuracy_image, stats)\n",
        "\n",
        "def _compare_inference_against_manual():\n",
        "  # load the manual segmentations\n",
        "  # can zip image_filenames and result_predictions because they are assumed to have the same length (result_predictions is instantiated using the image_filenames array as the parameter of the function `make_predictions`)\n",
        "  # Regis - 2021/07/05 plus qu'un seul appel à itertools.compress => on est certain de ne plus avoir de décalage\n",
        "  for image_filename, result_prediction in compress(zip(image_filenames, result_predictions), [r is not None for r in result_predictions]):\n",
        "    image_basename = image_filename.replace('.jpg', '').replace('.png', '')\n",
        "    json_filename = f'{image_basename}.json'\n",
        "    if not os.path.isfile(json_filename):\n",
        "      logging.warning('ignoring missing manual segmentation file: {}'.format(json_filename))\n",
        "      continue\n",
        "\n",
        "    # mt masks is the third key of the prediction tupple\n",
        "    prediction_mt_masks = Apex_points.utils._find_greatest_mt_masks(result_prediction[3])\n",
        "    ground_truth_mt_masks = Apex_points.utils._find_greatest_mt_masks(_json_file_to_mt_masks(json_filename))\n",
        "    accuracy_entries = [\n",
        "        ('apical', ground_truth_mt_masks[0], prediction_mt_masks[0]),\n",
        "        ('coronal', ground_truth_mt_masks[1], prediction_mt_masks[1]),\n",
        "        ('global', ground_truth_mt_masks[0] | ground_truth_mt_masks[1], prediction_mt_masks[0] | prediction_mt_masks[1])\n",
        "    ]\n",
        "\n",
        "    for category, ground_truth_mt_mask, prediction_mt_mask in accuracy_entries:\n",
        "      accuracy_image, stats = _compare_accuracy(ground_truth_mt_mask, prediction_mt_mask)\n",
        "      accuracy_path = os.path.join('Manual_comparison', f'{image_basename}-{category}.png')\n",
        "      accuracy_image.save(accuracy_path)\n",
        "\n",
        "      for (key, value) in stats.items():\n",
        "        dict_res[image_basename][f'{key}_{category}'] = value\n",
        "\n",
        "    # blend image\n",
        "    try:\n",
        "      initial_image = Image.open(image_filename)\n",
        "      global_accuracy_image = Image.open(os.path.join('Manual_comparison', f'{image_basename}-global.png'))\n",
        "      blend_image = Image.blend(initial_image, global_accuracy_image, 0.4)\n",
        "      blend_image.save(os.path.join('Manual_comparison', f'{image_basename}-blend.png'))\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    # show the last accuracy image (because plt.imshow only display one image)\n",
        "    if debug:\n",
        "      plt.imshow(accuracy_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkMaguXfB-4h"
      },
      "source": [
        "if run_mode == 'Comparison inference / manual':\n",
        "  _compare_inference_against_manual()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmypwYYsRgSt"
      },
      "source": [
        "## I3M on manual segmentation (if applicable: see `run_mode`[)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbEP_AJVRoyK"
      },
      "source": [
        "![ -d Manual_segmentation ] || mkdir Manual_segmentation\n",
        "\n",
        "def _localize_apices_from_json_file_path(annotations, engine, debug=False, output_dir='.', image_name=''):\n",
        "    # load the masks\n",
        "    width, height = annotations['imageWidth'], annotations['imageHeight']\n",
        "    mt_shapes = [shape for shape in annotations['shapes'] if shape['label'] == 'MT']\n",
        "    mt_masks = [Apex_points.utils._labelme_shape_to_mask(shape, width, height) for shape in mt_shapes]\n",
        "    image = Apex_points.utils._labelme_annotations_to_image(annotations)\n",
        "\n",
        "    return Apex_points.utils.localize_apices(image, mt_masks, engine, debug, output_dir, image_name)\n",
        "    \n",
        "def _localize_apices_from_json_file_paths(json_file_paths, engine, debug=False, output_dir='.', engine_name='apex points'):\n",
        "    import os\n",
        "    import json\n",
        "\n",
        "    # load all annotations\n",
        "    result = {}\n",
        "    all_annotations = {}\n",
        "    for json_file_path in json_file_paths:\n",
        "        if not os.path.exists(json_file_path):\n",
        "            continue\n",
        "\n",
        "        with open(json_file_path) as json_file:\n",
        "            filename = os.path.splitext(os.path.basename(json_file_path))[0]\n",
        "            try:\n",
        "                all_annotations[filename] = json.load(json_file)\n",
        "            except:\n",
        "                continue\n",
        "    if len(all_annotations) < 1:\n",
        "        return []\n",
        "\n",
        "    # perform analysis\n",
        "    for filename, annotations in all_annotations.items():\n",
        "        result[filename] = _localize_apices_from_json_file_path(annotations, engines[endpoints_detection_method], debug, output_dir, filename)\n",
        "    return result\n",
        "  \n",
        "if run_mode == 'I3M on manual segmentation':\n",
        "  manual_results = _localize_apices_from_json_file_paths(manual_segmentation_filenames, gradient_engine, debug=debug, output_dir='Manual_segmentation')\n",
        "  #files.download('./Manual_segmentation/manual_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kBhxzCXPYJU"
      },
      "source": [
        "## Store results as CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQcDr18Yt91v"
      },
      "source": [
        "# Romain - add on : write csv results\n",
        "import csv\n",
        "\n",
        "def _write_csv(keys, csv_output_path='./Predictions/results.csv', dict_res=dict_res):\n",
        "  with open(csv_output_path, \"w\") as dict_res_file:\n",
        "    writer = csv.writer(dict_res_file)\n",
        "    writer.writerow(['Radio_ID'] + [CSV_HUMAN_KEYS[key] for key in keys])\n",
        "    for radio_id in sorted(dict_res.keys()):\n",
        "      values = [dict_res[radio_id][key] if key in dict_res[radio_id] else '' for key in keys]\n",
        "      row = [radio_id]\n",
        "      row.extend(values)\n",
        "      writer.writerow(row)\n",
        "\n",
        "def _csv_inference():\n",
        "  _write_csv(['I3M', 'min_apex_opening', 'max_apex_opening', 'height'])\n",
        "\n",
        "def _csv_comparison_inference_manual():\n",
        "  _write_csv(['I3M', 'TP_apical', 'TN_apical', 'FP_apical', 'FN_apical', 'TP_coronal', 'TN_coronal', 'FP_coronal', 'FN_coronal', 'TP_global', 'TN_global', 'FP_global', 'FN_global', 'min_apex_opening', 'max_apex_opening', 'height'])\n",
        "\n",
        "def _csv_manual_i3m():\n",
        "  _write_csv(['I3M', 'min_apex_opening', 'max_apex_opening', 'height'], csv_output_path='./Manual_segmentation/manual_results.csv', dict_res=manual_results)\n",
        "\n",
        "csv_functions = {\n",
        "    'I3M on manual segmentation': _csv_manual_i3m,\n",
        "    'Comparison inference / manual': _csv_comparison_inference_manual,\n",
        "    'Inference': _csv_inference\n",
        "}\n",
        "\n",
        "CSV_HUMAN_KEYS = { 'I3M': 'I3M', 'TP_global': 'True positive', 'TN_global': 'True negative', 'FP_global': 'False positive', 'FN_global': 'False negative', 'TP_apical': 'True positive for apical mask', 'TN_apical': 'True negative for apical mask', 'FP_apical': 'False positive for apical mask', 'FN_apical': 'False negative for apical mask', 'TP_coronal': 'True positive for coronal mask', 'TN_coronal': 'True negative for coronal mask', 'FP_coronal': 'False positive for coronal mask', 'FN_coronal': 'False negative for coronal mask', 'min_apex_opening': 'Minimum apex opening (pixels)', 'max_apex_opening': 'Maximum apex opening (pixels)', 'height': 'Height (pixels)'}\n",
        "\n",
        "csv_functions[run_mode]()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePOFYsv93Oib"
      },
      "source": [
        "  ## Download final file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axXCmYjSG0UM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "0e8e1397-fbfb-4659-a92a-87977404a3e7"
      },
      "source": [
        "if run_mode == 'I3M on manual segmentation':\n",
        "  !zip -r manual_seg.zip Manual_segmentation/\n",
        "  files.download('manual_seg.zip')\n",
        "else : \n",
        "  !zip -r Predictions.zip Predictions/\n",
        "  files.download('Predictions.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: Predictions/ (stored 0%)\n",
            "updating: Predictions/results.csv (deflated 48%)\n",
            "updating: Predictions/417_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/454_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/418_r-pred-Gradient.jpg (deflated 3%)\n",
            "  adding: Predictions/432_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/420_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/470_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/429_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/414_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/446_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/524_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/419_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/488_l-pred-Gradient.jpg (deflated 1%)\n",
            "  adding: Predictions/510_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/442_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/472_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/479_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/427_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/484_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/486_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/439_r-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/444_l-pred-Gradient.jpg (deflated 2%)\n",
            "  adding: Predictions/515_r-pred-Gradient.jpg (deflated 2%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a76bcb41-c87c-4967-9320-af3700e74a91\", \"Predictions.zip\", 1985886)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vapd_6B6_6Bi"
      },
      "source": [
        "Last step: right click on Predictions.zip then download"
      ]
    }
  ]
}