{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL8hYgN5p1yM"
   },
   "source": [
    "# I3M Computation by 3R\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBfkphoH5XM9"
   },
   "source": [
    "This project will perform the mask_RCNN inference of MT in order to eventually compute I3M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E2L01ItCs2AF"
   },
   "outputs": [],
   "source": [
    "#@title Configuration { run: \"auto\" }\n",
    "run_mode = \"Comparaison inference / manual\" #@param [\"Inference\", \"Comparaison inference / manual\"]\n",
    "endpoints_detection_method = \"Gradient\" #@param [\"Ray tracing\", \"Skeleton\", \"Ray tracing + skeleton\", \"Gradient\"]\n",
    "HD = \"Image already HD\" #@param [\"Apply HD filter\", \"Image already HD\"]\n",
    "debug = True #@param {type: \"boolean\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp8nvnSgr_Bl"
   },
   "source": [
    "## Select Model + Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsCQrGOqkBWb",
    "outputId": "d35df40e-0b96-4b7c-c154-fa8f7e1a042e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "KnEJyrSEr2J7",
    "outputId": "5e2453c6-b5b4-4de9-df9c-b7007904319c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/*.jpg': No such file or directory\n",
      "/bin/bash: {}: command not found\n",
      "please select your Images and/or Manual segmentations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7a32bd04-b259-4b2d-af2c-61b9c11a57eb\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7a32bd04-b259-4b2d-af2c-61b9c11a57eb\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 006_r.jpg to 006_r.jpg\n",
      "Saving 006_r.json to 006_r.json\n",
      "Saving 008_l.jpg to 008_l.jpg\n",
      "Saving 008_l.json to 008_l.json\n",
      "Saving 021_r.jpg to 021_r.jpg\n",
      "Saving 021_r.json to 021_r.json\n",
      "Saving 022_r.jpg to 022_r.jpg\n",
      "Saving 022_r.json to 022_r.json\n",
      "Saving 024_l.jpg to 024_l.jpg\n",
      "Saving 024_l.json to 024_l.json\n",
      "Saving 026_l.jpg to 026_l.jpg\n",
      "Saving 026_l.json to 026_l.json\n",
      "Saving 027_r.jpg to 027_r.jpg\n",
      "Saving 027_r.json to 027_r.json\n",
      "Saving 029_l.jpg to 029_l.jpg\n",
      "Saving 029_l.json to 029_l.json\n",
      "Saving 036_r.jpg to 036_r.jpg\n",
      "Saving 036_r.json to 036_r.json\n",
      "Saving 038_r.jpg to 038_r.jpg\n",
      "Saving 038_r.json to 038_r.json\n",
      "Saving 043_l.jpg to 043_l.jpg\n",
      "Saving 043_l.json to 043_l.json\n",
      "Saving 055_r.jpg to 055_r.jpg\n",
      "Saving 055_r.json to 055_r.json\n",
      "Saving 066_r.jpg to 066_r.jpg\n",
      "Saving 066_r.json to 066_r.json\n",
      "Saving 070_r.jpg to 070_r.jpg\n",
      "Saving 070_r.json to 070_r.json\n",
      "Saving 074_l.jpg to 074_l.jpg\n",
      "Saving 074_l.json to 074_l.json\n",
      "Saving 085_l.jpg to 085_l.jpg\n",
      "Saving 085_l.json to 085_l.json\n",
      "Saving 090_r.jpg to 090_r.jpg\n",
      "Saving 090_r.json to 090_r.json\n",
      "Saving 107_l.jpg to 107_l.jpg\n",
      "Saving 107_l.json to 107_l.json\n",
      "Saving 107_r.jpg to 107_r.jpg\n",
      "Saving 107_r.json to 107_r.json\n",
      "Saving 110_r.jpg to 110_r.jpg\n",
      "Saving 110_r.json to 110_r.json\n",
      "Saving 111_l.jpg to 111_l.jpg\n",
      "Saving 111_l.json to 111_l.json\n",
      "Saving 116_l.jpg to 116_l.jpg\n",
      "Saving 116_l.json to 116_l.json\n",
      "Saving 116_r.jpg to 116_r.jpg\n",
      "Saving 116_r.json to 116_r.json\n",
      "Saving 122_r.jpg to 122_r.jpg\n",
      "Saving 122_r.json to 122_r.json\n",
      "Saving 124_l.jpg to 124_l.jpg\n",
      "Saving 124_l.json to 124_l.json\n",
      "Saving 124_r.jpg to 124_r.jpg\n",
      "Saving 124_r.json to 124_r.json\n",
      "Saving 126_r.jpg to 126_r.jpg\n",
      "Saving 126_r.json to 126_r.json\n",
      "Saving 130_r.jpg to 130_r.jpg\n",
      "Saving 130_r.json to 130_r.json\n",
      "Saving 140_r.jpg to 140_r.jpg\n",
      "Saving 140_r.json to 140_r.json\n",
      "Saving 142_r.jpg to 142_r.jpg\n",
      "Saving 142_r.json to 142_r.json\n",
      "Saving 145_r.jpg to 145_r.jpg\n",
      "Saving 145_r.json to 145_r.json\n",
      "Saving 151_r.jpg to 151_r.jpg\n",
      "Saving 151_r.json to 151_r.json\n",
      "Saving 158_l.jpg to 158_l.jpg\n",
      "Saving 158_l.json to 158_l.json\n",
      "Saving 160_l.jpg to 160_l.jpg\n",
      "Saving 160_l.json to 160_l.json\n",
      "Saving 177_l.jpg to 177_l.jpg\n",
      "Saving 177_l.json to 177_l.json\n",
      "Saving 182_r.jpg to 182_r.jpg\n",
      "Saving 182_r.json to 182_r.json\n",
      "Saving 185_l.jpg to 185_l.jpg\n",
      "Saving 185_l.json to 185_l.json\n",
      "Saving 187_r.jpg to 187_r.jpg\n",
      "Saving 187_r.json to 187_r.json\n",
      "Saving 192_r.jpg to 192_r.jpg\n",
      "Saving 192_r.json to 192_r.json\n",
      "Saving 208_l.jpg to 208_l.jpg\n",
      "Saving 208_l.json to 208_l.json\n",
      "Saving 217_l.jpg to 217_l.jpg\n",
      "Saving 217_l.json to 217_l.json\n",
      "Saving 224_r.jpg to 224_r.jpg\n",
      "Saving 224_r.json to 224_r.json\n",
      "Saving 228_r.jpg to 228_r.jpg\n",
      "Saving 228_r.json to 228_r.json\n",
      "Saving 229_r.jpg to 229_r.jpg\n",
      "Saving 229_r.json to 229_r.json\n",
      "Saving 244_l.jpg to 244_l.jpg\n",
      "Saving 244_l.json to 244_l.json\n",
      "Saving 247_l.jpg to 247_l.jpg\n",
      "Saving 247_l.json to 247_l.json\n",
      "Saving 250_l.jpg to 250_l.jpg\n",
      "Saving 250_l.json to 250_l.json\n",
      "Saving 260_l.jpg to 260_l.jpg\n",
      "Saving 260_l.json to 260_l.json\n",
      "Saving 270_l.jpg to 270_l.jpg\n",
      "Saving 270_l.json to 270_l.json\n",
      "Saving 278_r.jpg to 278_r.jpg\n",
      "Saving 278_r.json to 278_r.json\n",
      "Saving 279_r.jpg to 279_r.jpg\n",
      "Saving 279_r.json to 279_r.json\n",
      "Saving 303_r.jpg to 303_r.jpg\n",
      "Saving 303_r.json to 303_r.json\n",
      "Saving 307_l.jpg to 307_l.jpg\n",
      "Saving 307_l.json to 307_l.json\n",
      "Saving 309_l.jpg to 309_l.jpg\n",
      "Saving 309_l.json to 309_l.json\n",
      "Saving 331_r.jpg to 331_r.jpg\n",
      "Saving 331_r.json to 331_r.json\n",
      "Saving 334_r.jpg to 334_r.jpg\n",
      "Saving 334_r.json to 334_r.json\n",
      "Saving 349_r.jpg to 349_r.jpg\n",
      "Saving 349_r.json to 349_r.json\n",
      "Saving 366_l.jpg to 366_l.jpg\n",
      "Saving 366_l.json to 366_l.json\n",
      "Saving 370_r.jpg to 370_r.jpg\n",
      "Saving 370_r.json to 370_r.json\n",
      "Saving 381_l.jpg to 381_l.jpg\n",
      "Saving 381_l.json to 381_l.json\n",
      "Saving 381_r.jpg to 381_r.jpg\n",
      "Saving 381_r.json to 381_r.json\n",
      "Saving 384_l.jpg to 384_l.jpg\n",
      "Saving 384_l.json to 384_l.json\n",
      "Saving 390_r.jpg to 390_r.jpg\n",
      "Saving 390_r.json to 390_r.json\n",
      "Saving 397_r.jpg to 397_r.jpg\n",
      "Saving 397_r.json to 397_r.json\n",
      "Saving 406_l.jpg to 406_l.jpg\n",
      "Saving 406_l.json to 406_l.json\n",
      "Saving 413_l.jpg to 413_l.jpg\n",
      "Saving 413_l.json to 413_l.json\n",
      "Saving 414_l.jpg to 414_l.jpg\n",
      "Saving 414_l.json to 414_l.json\n",
      "Saving 417_r.jpg to 417_r.jpg\n",
      "Saving 417_r.json to 417_r.json\n",
      "Saving 418_r.jpg to 418_r.jpg\n",
      "Saving 418_r.json to 418_r.json\n",
      "Saving 419_l.jpg to 419_l.jpg\n",
      "Saving 419_l.json to 419_l.json\n",
      "Saving 420_r.jpg to 420_r.jpg\n",
      "Saving 420_r.json to 420_r.json\n",
      "Saving 421_r.jpg to 421_r.jpg\n",
      "Saving 421_r.json to 421_r.json\n",
      "Saving 427_l.jpg to 427_l.jpg\n",
      "Saving 427_l.json to 427_l.json\n",
      "Saving 429_r.jpg to 429_r.jpg\n",
      "Saving 429_r.json to 429_r.json\n",
      "Saving 432_l.jpg to 432_l.jpg\n",
      "Saving 432_l.json to 432_l.json\n",
      "Saving 433_l.jpg to 433_l.jpg\n",
      "Saving 433_l.json to 433_l.json\n",
      "Saving 439_r.jpg to 439_r.jpg\n",
      "Saving 439_r.json to 439_r.json\n",
      "Saving 442_l.jpg to 442_l.jpg\n",
      "Saving 442_l.json to 442_l.json\n",
      "Saving 444_l.jpg to 444_l.jpg\n",
      "Saving 444_l.json to 444_l.json\n",
      "Saving 446_l.jpg to 446_l.jpg\n",
      "Saving 446_l.json to 446_l.json\n",
      "Saving 454_r.jpg to 454_r.jpg\n",
      "Saving 454_r.json to 454_r.json\n",
      "Saving 470_r.jpg to 470_r.jpg\n",
      "Saving 470_r.json to 470_r.json\n",
      "Saving 472_l.jpg to 472_l.jpg\n",
      "Saving 472_l.json to 472_l.json\n",
      "Saving 479_r.jpg to 479_r.jpg\n",
      "Saving 479_r.json to 479_r.json\n",
      "Saving 484_l.jpg to 484_l.jpg\n",
      "Saving 484_l.json to 484_l.json\n",
      "Saving 486_l.jpg to 486_l.jpg\n",
      "Saving 486_l.json to 486_l.json\n",
      "Saving 486_r.jpg to 486_r.jpg\n",
      "Saving 486_r.json to 486_r.json\n",
      "Saving 488_l.jpg to 488_l.jpg\n",
      "Saving 488_l.json to 488_l.json\n",
      "Saving 510_l.jpg to 510_l.jpg\n",
      "Saving 510_l.json to 510_l.json\n",
      "Saving 515_r.jpg to 515_r.jpg\n",
      "Saving 515_r.json to 515_r.json\n",
      "Saving 524_l.jpg to 524_l.jpg\n",
      "Saving 524_l.json to 524_l.json\n",
      "Saving 524_r.jpg to 524_r.jpg\n",
      "Saving 524_r.json to 524_r.json\n",
      "User uploaded file \"006_r.jpg\" with length 9792 bytes\n",
      "User uploaded file \"006_r.json\" with length 20974 bytes\n",
      "User uploaded file \"008_l.jpg\" with length 9973 bytes\n",
      "User uploaded file \"008_l.json\" with length 22711 bytes\n",
      "User uploaded file \"021_r.jpg\" with length 10225 bytes\n",
      "User uploaded file \"021_r.json\" with length 22221 bytes\n",
      "User uploaded file \"022_r.jpg\" with length 10938 bytes\n",
      "User uploaded file \"022_r.json\" with length 23244 bytes\n",
      "User uploaded file \"024_l.jpg\" with length 10503 bytes\n",
      "User uploaded file \"024_l.json\" with length 21688 bytes\n",
      "User uploaded file \"026_l.jpg\" with length 10308 bytes\n",
      "User uploaded file \"026_l.json\" with length 21445 bytes\n",
      "User uploaded file \"027_r.jpg\" with length 9159 bytes\n",
      "User uploaded file \"027_r.json\" with length 29952 bytes\n",
      "User uploaded file \"029_l.jpg\" with length 9348 bytes\n",
      "User uploaded file \"029_l.json\" with length 17456 bytes\n",
      "User uploaded file \"036_r.jpg\" with length 9212 bytes\n",
      "User uploaded file \"036_r.json\" with length 18682 bytes\n",
      "User uploaded file \"038_r.jpg\" with length 11310 bytes\n",
      "User uploaded file \"038_r.json\" with length 24024 bytes\n",
      "User uploaded file \"043_l.jpg\" with length 10351 bytes\n",
      "User uploaded file \"043_l.json\" with length 26195 bytes\n",
      "User uploaded file \"055_r.jpg\" with length 11813 bytes\n",
      "User uploaded file \"055_r.json\" with length 32973 bytes\n",
      "User uploaded file \"066_r.jpg\" with length 11785 bytes\n",
      "User uploaded file \"066_r.json\" with length 34662 bytes\n",
      "User uploaded file \"070_r.jpg\" with length 10496 bytes\n",
      "User uploaded file \"070_r.json\" with length 32050 bytes\n",
      "User uploaded file \"074_l.jpg\" with length 10732 bytes\n",
      "User uploaded file \"074_l.json\" with length 31149 bytes\n",
      "User uploaded file \"085_l.jpg\" with length 11754 bytes\n",
      "User uploaded file \"085_l.json\" with length 33319 bytes\n",
      "User uploaded file \"090_r.jpg\" with length 10341 bytes\n",
      "User uploaded file \"090_r.json\" with length 27210 bytes\n",
      "User uploaded file \"107_l.jpg\" with length 12903 bytes\n",
      "User uploaded file \"107_l.json\" with length 24781 bytes\n",
      "User uploaded file \"107_r.jpg\" with length 13379 bytes\n",
      "User uploaded file \"107_r.json\" with length 25824 bytes\n",
      "User uploaded file \"110_r.jpg\" with length 10248 bytes\n",
      "User uploaded file \"110_r.json\" with length 16763 bytes\n",
      "User uploaded file \"111_l.jpg\" with length 10443 bytes\n",
      "User uploaded file \"111_l.json\" with length 20630 bytes\n",
      "User uploaded file \"116_l.jpg\" with length 12412 bytes\n",
      "User uploaded file \"116_l.json\" with length 33951 bytes\n",
      "User uploaded file \"116_r.jpg\" with length 12186 bytes\n",
      "User uploaded file \"116_r.json\" with length 32477 bytes\n",
      "User uploaded file \"122_r.jpg\" with length 10371 bytes\n",
      "User uploaded file \"122_r.json\" with length 25047 bytes\n",
      "User uploaded file \"124_l.jpg\" with length 9141 bytes\n",
      "User uploaded file \"124_l.json\" with length 24743 bytes\n",
      "User uploaded file \"124_r.jpg\" with length 9754 bytes\n",
      "User uploaded file \"124_r.json\" with length 21531 bytes\n",
      "User uploaded file \"126_r.jpg\" with length 8379 bytes\n",
      "User uploaded file \"126_r.json\" with length 25083 bytes\n",
      "User uploaded file \"130_r.jpg\" with length 7751 bytes\n",
      "User uploaded file \"130_r.json\" with length 21838 bytes\n",
      "User uploaded file \"140_r.jpg\" with length 8869 bytes\n",
      "User uploaded file \"140_r.json\" with length 24128 bytes\n",
      "User uploaded file \"142_r.jpg\" with length 10357 bytes\n",
      "User uploaded file \"142_r.json\" with length 23156 bytes\n",
      "User uploaded file \"145_r.jpg\" with length 9023 bytes\n",
      "User uploaded file \"145_r.json\" with length 24479 bytes\n",
      "User uploaded file \"151_r.jpg\" with length 8262 bytes\n",
      "User uploaded file \"151_r.json\" with length 28395 bytes\n",
      "User uploaded file \"158_l.jpg\" with length 9731 bytes\n",
      "User uploaded file \"158_l.json\" with length 28087 bytes\n",
      "User uploaded file \"160_l.jpg\" with length 11491 bytes\n",
      "User uploaded file \"160_l.json\" with length 25792 bytes\n",
      "User uploaded file \"177_l.jpg\" with length 9540 bytes\n",
      "User uploaded file \"177_l.json\" with length 29947 bytes\n",
      "User uploaded file \"182_r.jpg\" with length 10677 bytes\n",
      "User uploaded file \"182_r.json\" with length 26909 bytes\n",
      "User uploaded file \"185_l.jpg\" with length 10925 bytes\n",
      "User uploaded file \"185_l.json\" with length 29926 bytes\n",
      "User uploaded file \"187_r.jpg\" with length 10442 bytes\n",
      "User uploaded file \"187_r.json\" with length 27555 bytes\n",
      "User uploaded file \"192_r.jpg\" with length 10308 bytes\n",
      "User uploaded file \"192_r.json\" with length 28114 bytes\n",
      "User uploaded file \"208_l.jpg\" with length 10384 bytes\n",
      "User uploaded file \"208_l.json\" with length 28539 bytes\n",
      "User uploaded file \"217_l.jpg\" with length 9144 bytes\n",
      "User uploaded file \"217_l.json\" with length 25981 bytes\n",
      "User uploaded file \"224_r.jpg\" with length 9741 bytes\n",
      "User uploaded file \"224_r.json\" with length 26658 bytes\n",
      "User uploaded file \"228_r.jpg\" with length 9928 bytes\n",
      "User uploaded file \"228_r.json\" with length 28328 bytes\n",
      "User uploaded file \"229_r.jpg\" with length 11230 bytes\n",
      "User uploaded file \"229_r.json\" with length 30770 bytes\n",
      "User uploaded file \"244_l.jpg\" with length 9200 bytes\n",
      "User uploaded file \"244_l.json\" with length 23406 bytes\n",
      "User uploaded file \"247_l.jpg\" with length 10795 bytes\n",
      "User uploaded file \"247_l.json\" with length 26728 bytes\n",
      "User uploaded file \"250_l.jpg\" with length 10964 bytes\n",
      "User uploaded file \"250_l.json\" with length 20532 bytes\n",
      "User uploaded file \"260_l.jpg\" with length 11550 bytes\n",
      "User uploaded file \"260_l.json\" with length 26911 bytes\n",
      "User uploaded file \"270_l.jpg\" with length 9679 bytes\n",
      "User uploaded file \"270_l.json\" with length 20185 bytes\n",
      "User uploaded file \"278_r.jpg\" with length 10725 bytes\n",
      "User uploaded file \"278_r.json\" with length 21536 bytes\n",
      "User uploaded file \"279_r.jpg\" with length 8882 bytes\n",
      "User uploaded file \"279_r.json\" with length 20341 bytes\n",
      "User uploaded file \"303_r.jpg\" with length 11102 bytes\n",
      "User uploaded file \"303_r.json\" with length 20885 bytes\n",
      "User uploaded file \"307_l.jpg\" with length 11514 bytes\n",
      "User uploaded file \"307_l.json\" with length 21027 bytes\n",
      "User uploaded file \"309_l.jpg\" with length 9482 bytes\n",
      "User uploaded file \"309_l.json\" with length 20616 bytes\n",
      "User uploaded file \"331_r.jpg\" with length 9963 bytes\n",
      "User uploaded file \"331_r.json\" with length 24153 bytes\n",
      "User uploaded file \"334_r.jpg\" with length 11337 bytes\n",
      "User uploaded file \"334_r.json\" with length 27173 bytes\n",
      "User uploaded file \"349_r.jpg\" with length 9798 bytes\n",
      "User uploaded file \"349_r.json\" with length 22334 bytes\n",
      "User uploaded file \"366_l.jpg\" with length 11223 bytes\n",
      "User uploaded file \"366_l.json\" with length 20590 bytes\n",
      "User uploaded file \"370_r.jpg\" with length 9227 bytes\n",
      "User uploaded file \"370_r.json\" with length 20448 bytes\n",
      "User uploaded file \"381_l.jpg\" with length 8842 bytes\n",
      "User uploaded file \"381_l.json\" with length 21417 bytes\n",
      "User uploaded file \"381_r.jpg\" with length 9247 bytes\n",
      "User uploaded file \"381_r.json\" with length 21336 bytes\n",
      "User uploaded file \"384_l.jpg\" with length 9113 bytes\n",
      "User uploaded file \"384_l.json\" with length 21390 bytes\n",
      "User uploaded file \"390_r.jpg\" with length 9008 bytes\n",
      "User uploaded file \"390_r.json\" with length 22114 bytes\n",
      "User uploaded file \"397_r.jpg\" with length 9807 bytes\n",
      "User uploaded file \"397_r.json\" with length 18745 bytes\n",
      "User uploaded file \"406_l.jpg\" with length 9209 bytes\n",
      "User uploaded file \"406_l.json\" with length 19654 bytes\n",
      "User uploaded file \"413_l.jpg\" with length 13289 bytes\n",
      "User uploaded file \"413_l.json\" with length 26818 bytes\n",
      "User uploaded file \"414_l.jpg\" with length 9877 bytes\n",
      "User uploaded file \"414_l.json\" with length 23723 bytes\n",
      "User uploaded file \"417_r.jpg\" with length 10703 bytes\n",
      "User uploaded file \"417_r.json\" with length 21880 bytes\n",
      "User uploaded file \"418_r.jpg\" with length 13136 bytes\n",
      "User uploaded file \"418_r.json\" with length 27805 bytes\n",
      "User uploaded file \"419_l.jpg\" with length 9979 bytes\n",
      "User uploaded file \"419_l.json\" with length 21444 bytes\n",
      "User uploaded file \"420_r.jpg\" with length 10555 bytes\n",
      "User uploaded file \"420_r.json\" with length 23114 bytes\n",
      "User uploaded file \"421_r.jpg\" with length 10005 bytes\n",
      "User uploaded file \"421_r.json\" with length 22679 bytes\n",
      "User uploaded file \"427_l.jpg\" with length 8513 bytes\n",
      "User uploaded file \"427_l.json\" with length 19194 bytes\n",
      "User uploaded file \"429_r.jpg\" with length 9223 bytes\n",
      "User uploaded file \"429_r.json\" with length 24869 bytes\n",
      "User uploaded file \"432_l.jpg\" with length 10568 bytes\n",
      "User uploaded file \"432_l.json\" with length 26332 bytes\n",
      "User uploaded file \"433_l.jpg\" with length 12004 bytes\n",
      "User uploaded file \"433_l.json\" with length 24865 bytes\n",
      "User uploaded file \"439_r.jpg\" with length 9079 bytes\n",
      "User uploaded file \"439_r.json\" with length 20499 bytes\n",
      "User uploaded file \"442_l.jpg\" with length 9204 bytes\n",
      "User uploaded file \"442_l.json\" with length 22418 bytes\n",
      "User uploaded file \"444_l.jpg\" with length 10025 bytes\n",
      "User uploaded file \"444_l.json\" with length 24219 bytes\n",
      "User uploaded file \"446_l.jpg\" with length 9533 bytes\n",
      "User uploaded file \"446_l.json\" with length 20936 bytes\n",
      "User uploaded file \"454_r.jpg\" with length 8247 bytes\n",
      "User uploaded file \"454_r.json\" with length 18656 bytes\n",
      "User uploaded file \"470_r.jpg\" with length 9863 bytes\n",
      "User uploaded file \"470_r.json\" with length 30427 bytes\n",
      "User uploaded file \"472_l.jpg\" with length 13950 bytes\n",
      "User uploaded file \"472_l.json\" with length 35097 bytes\n",
      "User uploaded file \"479_r.jpg\" with length 8855 bytes\n",
      "User uploaded file \"479_r.json\" with length 31243 bytes\n",
      "User uploaded file \"484_l.jpg\" with length 13504 bytes\n",
      "User uploaded file \"484_l.json\" with length 34578 bytes\n",
      "User uploaded file \"486_l.jpg\" with length 9278 bytes\n",
      "User uploaded file \"486_l.json\" with length 25010 bytes\n",
      "User uploaded file \"486_r.jpg\" with length 8831 bytes\n",
      "User uploaded file \"486_r.json\" with length 23192 bytes\n",
      "User uploaded file \"488_l.jpg\" with length 9600 bytes\n",
      "User uploaded file \"488_l.json\" with length 24144 bytes\n",
      "User uploaded file \"510_l.jpg\" with length 11902 bytes\n",
      "User uploaded file \"510_l.json\" with length 28117 bytes\n",
      "User uploaded file \"515_r.jpg\" with length 8548 bytes\n",
      "User uploaded file \"515_r.json\" with length 23228 bytes\n",
      "User uploaded file \"524_l.jpg\" with length 8850 bytes\n",
      "User uploaded file \"524_l.json\" with length 24695 bytes\n",
      "User uploaded file \"524_r.jpg\" with length 9091 bytes\n",
      "User uploaded file \"524_r.json\" with length 22237 bytes\n"
     ]
    }
   ],
   "source": [
    "!rm /content/*.jpg || {}\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print('please select your Images and/or Manual segmentations')\n",
    "uploaded = files.upload()\n",
    "filenames = list(uploaded.keys())\n",
    "image_filenames = [filename for filename in filenames if filename.endswith('.jpg') or filename.endswith('.png')]\n",
    "manual_segmentation_filenames = [filename for filename in filenames if filename.endswith('.json')]\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LMZuUZFovoGI"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f0kFZGg0xl-8"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':\"10jP0flXeozBQUXcx6Q7CUonaQiTZAjrV\"})  # I3M - JUNE 2021\n",
    "#downloaded = drive.CreateFile({'id':\"1CAn1PBg_OrGhN41LP51UNY46zTsi3xo-\"})  # mask_rcnn_tooth_segmentation_0006\n",
    "#downloaded = drive.CreateFile({'id':\"19euYX5zo1ty5HacZ0mwXuUoHygFaWLkV\"}) # mask_rcnn_tooth_segmentation_0008\n",
    "#downloaded = drive.CreateFile({'id':\"1o6uigkw3ZSN2H1vBRv5-uqLX3UiD7m-w\"}) # mask_rcnn_tooth_segmentation_0018\n",
    "#downloaded = drive.CreateFile({'id':\"1eFsvwd7knZBOpUTO_7iwIcipnvE7Cq1W\"}) # mask_rcnn_tooth_segmentation_0019\n",
    "\n",
    "downloaded.GetContentFile('I3M.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POZpNGARp1yV"
   },
   "source": [
    "## Install backbone in Google Colab\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xYnZTLMgp1yV"
   },
   "outputs": [],
   "source": [
    "#%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PVdnlB7p1yY",
    "outputId": "fc137353-6ef7-4726-e8b5-4c0df7974a76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mask_RCNN'...\n",
      "remote: Enumerating objects: 956, done.\u001b[K\n",
      "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
      "Receiving objects: 100% (956/956), 125.23 MiB | 33.80 MiB/s, done.\n",
      "Resolving deltas: 100% (562/562), done.\n",
      "/content/Mask_RCNN\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.23)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
      "Requirement already satisfied: tensorflow>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.4.3)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n",
      "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.5.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.34.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.12.4)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.7.4.3)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.2)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.36.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->-r requirements.txt (line 10)) (1.5.2)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.7.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.6.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.18)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (57.0.0)\n",
      "Requirement already satisfied: Sphinx>=1.3; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n",
      "Requirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.3.1)\n",
      "Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.6.1)\n",
      "Requirement already satisfied: requests; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.23.0)\n",
      "Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.0)\n",
      "Requirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.5.0)\n",
      "Collecting nose>=0.10.1; extra == \"all\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 5.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.6.3)\n",
      "Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.10.1)\n",
      "Collecting ipyparallel; extra == \"all\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e9/03a9189eb39276396309faf28bf833b4328befe4513bbf375b811a36a076/ipyparallel-6.3.0-py3-none-any.whl (199kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 8.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.4)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython[all]->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.2.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (20.9)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.4)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.11.3)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.9.1)\n",
      "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.17.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.1.0)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.7.1)\n",
      "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.10.1)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.3.5)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.4.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n",
      "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.9.0)\n",
      "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (22.1.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.5.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.4.1)\n",
      "Installing collected packages: nose, ipyparallel\n",
      "Successfully installed ipyparallel-6.3.0 nose-1.3.7\n",
      "WARNING:root:Fail load requirements file, so using default ones.\n",
      "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  % (opt, underscore_opt))\n",
      "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n",
      "  % (opt, underscore_opt))\n",
      "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n",
      "  % (opt, underscore_opt))\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating mask_rcnn.egg-info\n",
      "writing mask_rcnn.egg-info/PKG-INFO\n",
      "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
      "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
      "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/mrcnn\n",
      "copying mrcnn/utils.py -> build/lib/mrcnn\n",
      "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
      "copying mrcnn/config.py -> build/lib/mrcnn\n",
      "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
      "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
      "copying mrcnn/model.py -> build/lib/mrcnn\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/mask_rcnn-2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing mask_rcnn-2.1-py3.7.egg\n",
      "Copying mask_rcnn-2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding mask-rcnn 2.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
      "Processing dependencies for mask-rcnn==2.1\n",
      "Finished processing dependencies for mask-rcnn==2.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/matterport/Mask_RCNN\n",
    "%cd Mask_RCNN\n",
    "!pip3 install -r requirements.txt\n",
    "!python3 setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "txm9YcQPp1yZ",
    "outputId": "4950e1df-c05d-43e8-d172-c799c7a26702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cocoapi'...\n",
      "remote: Enumerating objects: 975, done.\u001b[K\n",
      "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
      "Receiving objects: 100% (975/975), 11.72 MiB | 25.82 MiB/s, done.\n",
      "Resolving deltas: 100% (576/576), done.\n",
      "/content/Mask_RCNN/cocoapi/PythonAPI\n",
      "python setup.py build_ext --inplace\n",
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/Mask_RCNN/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
      "rm -rf build\n",
      "/content/Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cocodataset/cocoapi.git\n",
    "%cd cocoapi/PythonAPI\n",
    "!make\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kkJgQ5CTiAn",
    "outputId": "ca5bcf63-d705-491c-aceb-9b99bd808349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Apex_points'...\n",
      "warning: redirecting to https://github.com/iozzinor/Apex_points.git/\n",
      "remote: Enumerating objects: 87, done.\u001b[K\n",
      "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
      "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
      "remote: Total 87 (delta 43), reused 70 (delta 26), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (87/87), done.\n",
      "Collecting scikit-image==0.18.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/01/3a830f3df578ea3ed94ee7fd9f91e85c3dec2431d8548ab1c91869e51450/scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
      "\u001b[K     |████████████████████████████████| 29.2MB 106kB/s \n",
      "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (1.19.5)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (3.2.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (2021.6.14)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (2.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (2.5.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1) (7.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (2.4.7)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image==0.18.1) (4.4.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1) (1.15.0)\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scikit-image\n",
      "  Found existing installation: scikit-image 0.16.2\n",
      "    Uninstalling scikit-image-0.16.2:\n",
      "      Successfully uninstalled scikit-image-0.16.2\n",
      "Successfully installed scikit-image-0.18.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://www.github.com/iozzinor/Apex_points\n",
    "!pip3 install scikit-image==0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ywia4bNnG0Q",
    "outputId": "087c9740-a5fb-4ed9-bce4-c45bdf760cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
      "  Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
      "Uninstalling Keras-2.4.3:\n",
      "  Successfully uninstalled Keras-2.4.3\n",
      "Collecting keras==2.2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 5.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
      "Collecting keras-applications>=1.0.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 4.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.5) (1.5.2)\n",
      "Installing collected packages: keras-applications, keras\n",
      "Successfully installed keras-2.2.5 keras-applications-1.0.8\n",
      "Collecting tensorflow==1.15.0rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/a9/a5ffe715d3475fed0a79be8e13ef638abbd1c013fdbe8f43892f06336b82/tensorflow-1.15.0rc2-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
      "\u001b[K     |████████████████████████████████| 412.3MB 33kB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.1.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.12.0)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 24.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.34.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (3.12.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.1.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 36.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.36.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.15.0)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc2) (1.19.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (57.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.3.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0rc2) (3.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (4.5.0)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0rc2) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.4.1)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=70d4d7c9fd8318be778856ab20f6696585f210863c87926656dfd9485713267f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.0rc2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow\n",
      "  Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0rc2 tensorflow-estimator-1.15.1\n",
      "Collecting h5py==2.10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 6.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
      "Installing collected packages: h5py\n",
      "  Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "Successfully installed h5py-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall -y keras-nightly\n",
    "!pip3 uninstall -y keras\n",
    "!pip3 install keras==2.2.5\n",
    "\n",
    "#!pip3 uninstall -y tensorflow\n",
    "!pip3 install tensorflow==1.15.0rc2\n",
    "\n",
    "!pip3 install h5py==2.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA6fcj2fp1yb"
   },
   "source": [
    "## Import and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sVT6Z0OrGKX",
    "outputId": "61854be4-21f1-4e49-f623-0590603f48e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "import Apex_points\n",
    "from Apex_points.ray_tracing import localize_apices_engine as ray_tracing_engine\n",
    "from Apex_points.skeleton import localize_apices_engine as skeleton_engine\n",
    "from Apex_points.gradient import localize_apices_engine as gradient_engine\n",
    "\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dGBBIAVrPtD",
    "outputId": "a094da31-6c4a-40c7-ac0a-2cc4fe8f203f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           tooth_segmentation\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                250\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## UPDATE WT\n",
    "class RadioConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"tooth_segmentation\"\n",
    "    \n",
    "    NUM_CLASSES = 1 + 1 #NB : 2 because MT and JAD\n",
    "\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "    STEPS_PER_EPOCH = 250\n",
    "\n",
    "    # New\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    IMAGE_MIN_DIM = 256\n",
    "\n",
    "config = RadioConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YB98jKFyhPs"
   },
   "source": [
    "## Inference production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3zL0OJXzLyR",
    "outputId": "96400180-3468-4584-ca7a-3755a57b6284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8mFOKTpylRy",
    "outputId": "063287c2-70f8-4537-aec7-f889b2fc9933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Loading weights from  I3M.h5\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"\"\n",
    "class InferenceConfig(RadioConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "model_path = \"I3M.h5\"\n",
    "#model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AVQEn_fo1a-v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import exposure\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "cnames = ['BG', 'MT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZjI2WcPv2kRY"
   },
   "outputs": [],
   "source": [
    "# Romain - add on : create dict\n",
    "#\n",
    "# Regis - edit: store results in the global variable as dictionnaries. dict_res is no longer a list but a dict, whose keys are the radio UNIQUE identifiers\n",
    "# Advantages: no longer need to maintain two arrays side by side ('Radio_ID' and 'I3M') with the need to have same length and order\n",
    "dict_res = {}\n",
    "\n",
    "def adaptHist(path_image): \n",
    "    img_to_pred_arr = np.array(Image.open(path_image).convert('RGB'))\n",
    "    img_to_pred_adapthist = exposure.equalize_adapthist(img_to_pred_arr/np.max(img_to_pred_arr))\n",
    "    img_to_pred_adapthist = Image.fromarray((img_to_pred_adapthist * 255).astype(np.uint8))\n",
    "    return img_to_pred_adapthist\n",
    "\n",
    "\n",
    "def make_predictions(image_paths):\n",
    "  \"\"\"\n",
    "  Returns\n",
    "  -------\n",
    "    The result of the function `make_visualisations`\n",
    "  \"\"\"\n",
    "  #images = [Image.open(image_path).convert('RGB') for image_path in image_paths]\n",
    "  #names = [os.path.splitext(os.path.basename(filename))[0] for filename in image_paths]\n",
    "  #np_images = [np.array(image) for image in images]\n",
    "  \n",
    "  if(HD==\"Image already HD\"):\n",
    "    images = [Image.open(image_path).convert('RGB') for image_path in image_paths]\n",
    "  else: \n",
    "    images = [adaptHist(image_path) for image_path in image_paths]\n",
    "\n",
    "  names = [os.path.splitext(os.path.basename(filename))[0] for filename in image_paths]\n",
    "  np_images = [np.array(image) for image in images]\n",
    "  \n",
    "  results = [model.detect([image], verbose=1) for image in np_images]\n",
    "  return make_visualizations(results, images, names)\n",
    "\n",
    "def make_visualizations(results, images, names):\n",
    "   \"\"\"\n",
    "   Returns\n",
    "   -------\n",
    "   An array of the results returned by `make_prediction_image`\n",
    "   \"\"\"\n",
    "   return [make_prediction_image(r[0], i, name) for r, i, name in zip(results, images, names)]\n",
    "\n",
    "def make_prediction_image(r, img_to_pred, image_name, dict_res=dict_res):\n",
    "  \"\"\"\n",
    "  Returns\n",
    "  -------\n",
    "    None in case of failure.\n",
    "    Else: a tupple of :\n",
    "    - the output image, as a PILLOW object.\n",
    "    - the prediction engine result\n",
    "    - the model result\n",
    "    - an array of the mineralized tissue masks\n",
    "  \"\"\"\n",
    "  # masks has a shape (height, width, number of detected classes)\n",
    "  masks = r['masks']\n",
    "  # masks is now an array with 'number of detected classes' elements\n",
    "  # each element has a shape (height, width)\n",
    "  masks_count = masks.shape[-1]\n",
    "  masks = [mask.reshape((config.IMAGE_MAX_DIM, config.IMAGE_MAX_DIM)) for mask in np.split(masks, masks_count, axis=-1)]\n",
    "  class_ids = r['class_ids']\n",
    "  mt_masks = []\n",
    "  for i, mask in enumerate(masks):\n",
    "      current_class_name = cnames[class_ids[i]]\n",
    "      if current_class_name == 'MT':\n",
    "          mt_masks.append(mask)\n",
    "\n",
    "  apices_result = apex_prediction_image(img_to_pred, mt_masks, image_name)\n",
    "  if apices_result is not None:\n",
    "    dict_res[image_name] = {'I3M': apices_result['I3M']}\n",
    "    return apices_result['output_image'], apices_result, r, mt_masks\n",
    "  return None\n",
    "            \n",
    "def apex_prediction_image(img_to_pred, mt_masks, image_name):\n",
    "    if endpoints_detection_method == 'Ray tracing':\n",
    "        return Apex_points.localize_apices(img_to_pred, mt_masks, ray_tracing_engine, debug, '.', image_name)\n",
    "    elif endpoints_detection_method == 'Skeleton':\n",
    "        return Apex_points.localize_apices(img_to_pred, mt_masks, skeleton_engine, debug, '.', image_name)\n",
    "    elif endpoints_detection_method == 'Ray tracing + skeleton':\n",
    "        width, height = img_to_pred.size\n",
    "        result_image = Image.new('RGB', (width * 2, height))\n",
    "        global_result = { 'I3M': -1 }\n",
    "        apices_result = Apex_points.localize_apices(img_to_pred, mt_masks, ray_tracing_engine, debug, '.', image_name)\n",
    "        if apices_result is not None:\n",
    "            result_image.paste(apices_result['output_image'].resize((width, height)), (0, 0))\n",
    "            global_result['I3M'] = apices_result['I3M']\n",
    "        apices_result = Apex_points.localize_apices(img_to_pred, mt_masks, skeleton_engine, debug, '.', image_name)\n",
    "        if apices_result is not None:\n",
    "            result_image.paste(apices_result['output_image'].resize((width, height)), (width, 0))\n",
    "        global_result['output_image'] = result_image\n",
    "        return global_result\n",
    "    elif endpoints_detection_method == 'Gradient':\n",
    "      return Apex_points.localize_apices(img_to_pred, mt_masks, gradient_engine, debug, '.', image_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lxAuMhSQs1wu"
   },
   "outputs": [],
   "source": [
    "image_paths = image_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVQWmvV12xeu",
    "outputId": "8ae90622-a6ca-43fc-81c6-cef859814cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "YES\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n",
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -1.41976  max:    2.16878  float32\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "result_predictions = make_predictions(image_filenames)\n",
    "result_images = [result[0] for result in result_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dD2QKX8R2yV2"
   },
   "outputs": [],
   "source": [
    "# save the results\n",
    "![ -d Predictions ] || mkdir Predictions\n",
    "for i, result_image in enumerate(result_images):\n",
    "  if result_image is None:\n",
    "    print(f'image at index {i} is None')\n",
    "    continue\n",
    "  try: \n",
    "    filename = image_filenames[i]\n",
    "    image_name, image_extension = os.path.splitext(filename) # get the image name from the filename\n",
    "    image_extension = image_extension[1:] # remove the leading dot\n",
    "\n",
    "    output_path = os.path.join('Predictions', f'{image_name}-pred-{endpoints_detection_method}.{image_extension}')\n",
    "    result_image.save(output_path, quality=100, subsampling=0)\n",
    "    print(f'saved result at {output_path}')\n",
    "  except Exception as exception:\n",
    "    print(f'error in saving: {exception}')\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APcPffdA-fhI"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show at max 4 images\n",
    "def _show_images(images=None):\n",
    "  if images is None:\n",
    "    images = result_images\n",
    "  images_to_show = [image for image in images if image is not None][:4]\n",
    "  grid_size = 1 if len(images_to_show) < 2 else 2\n",
    "  fig, _ = plt.subplots(ncols=grid_size, nrows=grid_size)\n",
    "  for i, image in enumerate(images_to_show):\n",
    "      fig.axes[i].imshow(image)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TqMgAAX-rX2"
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "  _show_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLxeFQVK8F7T"
   },
   "source": [
    "# Comparaison inference / manual (if applicable: see `run_mode`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO8rP5V75LKX"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Regis - add on: compute area accuracy\n",
    "\n",
    "import logging\n",
    "import json\n",
    "\n",
    "def _create_merged_mask(mt_masks):\n",
    "  # create the composite image (logical or of all masks)\n",
    "  mt_mask = np.zeros_like(mt_masks[0])\n",
    "  for mask in mt_masks:\n",
    "    mt_mask |= mask\n",
    "  return mt_mask\n",
    "\n",
    "def _shapes_to_masks(shapes, width, height):\n",
    "  masks = []\n",
    "  for shape in shapes:\n",
    "    mask = Image.new('L', (width, height))\n",
    "    points = [tuple(point) for point in shape['points']]\n",
    "    ImageDraw.Draw(mask).polygon(points, fill=1)\n",
    "    masks.append(np.array(mask))\n",
    "  return masks\n",
    "\n",
    "  masks = np.zeros((height, width))\n",
    "\n",
    "def _json_file_to_mt_mask(json_filename):\n",
    "    with open(json_filename) as json_file:\n",
    "      annotations = json.load(json_file)\n",
    "    shapes = annotations['shapes']\n",
    "    mt_shapes = [shape for shape in shapes if shape['label'] == 'MT']\n",
    "    mt_masks = _shapes_to_masks(mt_shapes, annotations['imageWidth'], annotations['imageHeight'])\n",
    "    return _create_merged_mask(mt_masks)\n",
    "\n",
    "def _number_pixels_in_mask(mask):\n",
    "  \"\"\"\n",
    "  Parameters\n",
    "  ----------\n",
    "  mask: np.array\n",
    "    A binary mask (or an int mask: any strict positive value will be considered as True).\n",
    "  \"\"\"\n",
    "  return len(list(zip(*np.where(mask>0))))\n",
    "\n",
    "def _compare_inference_against_manual():\n",
    "  # mt masks is the third key of the prediction tupple\n",
    "  merged_masks = [_create_merged_mask(result_prediction[3]) for result_prediction in result_predictions]\n",
    "  _show_images(merged_masks)\n",
    "\n",
    "  # load the manual segmentations\n",
    "  # can zip image_filenames and result_predictions because they are assumed to have the same length (result_predictions is instantiated using the image_filenames array as the parameter of the function `make_predictions`)\n",
    "  for image_filename, prediction_mt_mask, result_prediction in zip(image_filenames, merged_masks, result_predictions):\n",
    "    image_basename = image_filename.replace('.jpg', '').replace('.png', '')\n",
    "    json_filename = '{}.json'.format(image_basename)\n",
    "    if not os.path.isfile(json_filename):\n",
    "      logging.warning('ignoring missing manual segmentation file: {}'.format(json_filename))\n",
    "      continue\n",
    "    ground_truth_mt_mask = _json_file_to_mt_mask(json_filename)\n",
    "\n",
    "    union = ground_truth_mt_mask | prediction_mt_mask\n",
    "    intersection = ground_truth_mt_mask & prediction_mt_mask\n",
    "\n",
    "    tp_mask = intersection\n",
    "    tn_mask = np.where(union>0,0,1)\n",
    "    fp_mask = union & np.where(ground_truth_mt_mask>0,0,1)\n",
    "    fn_mask = union & np.where(prediction_mt_mask>0,0,1)\n",
    "\n",
    "    accuracy_image = Image.new('RGB', (union.shape[1], union.shape[0]))\n",
    "    # TODO: refactoriser bibliothèque Apex_points pour ne plus appeler la fonction \"privée\" Apex_points.utils._apply_mask_to_image.\n",
    "    Apex_points.utils._apply_mask_to_image(accuracy_image, tp_mask, (0, 255, 0), 1) # true positives: green\n",
    "    Apex_points.utils._apply_mask_to_image(accuracy_image, tn_mask, (0, 0, 0), 1) # true negatives: black\n",
    "    Apex_points.utils._apply_mask_to_image(accuracy_image, fn_mask, (255, 0, 0), 1) # false negatives (missing pixels): red\n",
    "    Apex_points.utils._apply_mask_to_image(accuracy_image, fp_mask, (255, 128, 0), 1) # false positives: orange\n",
    "\n",
    "    stat_masks = {'TP': tp_mask, 'TN': tn_mask, 'FP': fp_mask, 'FN': fn_mask}\n",
    "\n",
    "    for (key, mask) in stat_masks.items():\n",
    "      dict_res[image_basename][key] = _number_pixels_in_mask(mask)\n",
    "\n",
    "    if debug:\n",
    "      plt.imshow(accuracy_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkMaguXfB-4h"
   },
   "outputs": [],
   "source": [
    "if run_mode == 'Comparaison inference / manual':\n",
    "  _compare_inference_against_manual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQcDr18Yt91v"
   },
   "outputs": [],
   "source": [
    "# Romain - add on : write csv results\n",
    "import csv\n",
    "\n",
    "keys = ['I3M', 'TP', 'TN', 'FP', 'FN'] if run_mode == 'Comparaison inference / manual' else ['I3M']\n",
    "\n",
    "dict_res_file = open(\"./Predictions/results.csv\", \"w\")\n",
    "writer = csv.writer(dict_res_file)\n",
    "writer.writerow(['Radio_ID'] + keys)\n",
    "for radio_id in sorted(dict_res.keys()):\n",
    "  values = [dict_res[radio_id][key] if key in dict_res[radio_id] else '' for key in keys]\n",
    "  row = [radio_id]\n",
    "  row.extend(values)\n",
    "  writer.writerow(row)\n",
    "dict_res_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePOFYsv93Oib"
   },
   "source": [
    "  ## Download final file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83i7GsLthgDt"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H87na9VX22is"
   },
   "outputs": [],
   "source": [
    "!zip -r Predictions.zip Predictions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbE2R-plkBpk"
   },
   "outputs": [],
   "source": [
    "files.download('Predictions.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vapd_6B6_6Bi"
   },
   "source": [
    "Last step: right click on Predictions.zip then download"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mp8nvnSgr_Bl",
    "POZpNGARp1yV",
    "MA6fcj2fp1yb",
    "tLxeFQVK8F7T"
   ],
   "name": "I3M by R3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
